{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (To Be Deleted) Markdown Stylization (note spacing)\n",
    "## Chapter = 2 (Number_Shift3) (note spacing)\n",
    "### Subtitle = 3 (Number_Shift3) (note spacing)\n",
    "*Italicized* = 1 (Star_Shift8) around\n",
    "\n",
    "**Bold** = 2 (Star_Shift8) around OR as #### Heading (note spacing)\n",
    "\n",
    "***Italicized & Bold*** = 3 (Star_Shift8) around\n",
    "\n",
    "`Gray Square` = 1 (GraveAccent_NoShift~) around\n",
    "\n",
    "Y (Code Type) ↔ M (Markdown Type)\n",
    "\n",
    "> Gray Bar = 1 (GreaterThan_Shift.) before\n",
    ">> Gray Bar = 2 (GreaterThan_Shift.) before, under above to be in same set\n",
    ">>> Gray Bar = 3 (GreaterThan_Shift.)\n",
    "\n",
    "    Indentation is always 4 (Spaces) before, under above to be in same set; changes the font\n",
    " \n",
    "**▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing our data and setting the \"Id\" column as our index\n",
    "df = pd.read_csv('kc_house_data.csv', index_col = 'Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "built = (dup.groupby(\"Id\")).Yr_Built.mean()\n",
    "renovated = (dup.groupby(\"Id\")).Yr_Renovated.mean()\n",
    "\n",
    "average = filter(lambda x: x > 0, renovated)\n",
    "\n",
    "oldest = df.loc[(df.Yr_Built == df.Yr_Built.min()) & (df.Id.duplicated(False))]\n",
    "\n",
    "display(oldest)\n",
    "\n",
    "\n",
    "print(round(built.mean(), ), built.min(), built.max())\n",
    "print(renovated.count(), min(average), renovated.max())\n",
    "print(\"\")\n",
    "print(oldest.Date.min().date())\n",
    "\n",
    "#print(\"The oldest house resold was first built in\", oldest.first().mean(), \"and sold\", oldest.last().mean(),\"years later!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeing our reduced DataFrame's descriptive stats and preview\n",
    "display(df.info(), \n",
    "        pd.DataFrame(data = df.nunique().sort_values(), columns = ['Counts']).transpose(),\n",
    "        df.describe(), \n",
    "        df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Comparing predicted price vs actual price\", fontdict={'fontsize': 20}), plt.xlabel(\"Values\"), plt.ylabel(\"Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running a train-test-split model validation with our selected features\n",
    "def linear_regression(X, y):\n",
    "    \n",
    "    train_err = []\n",
    "    test_err = []\n",
    "    sample = y.sample(n=200) #Generating 200 random rows in a sample list\n",
    "    for i in sample: #i = individual house row\n",
    "        temp_train_err = []\n",
    "        temp_test_err = []\n",
    "        #Performing the test 100 times to account for any particularly good/bad models that might have might have resulted from poor/good splits in the data\n",
    "        for model in range(100):       \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 123) #Seed for reproducibility\n",
    "            linreg = LinearRegression()\n",
    "            linreg.fit(X_train, y_train) #Fitting the model to the train data\n",
    "            y_hat_train = linreg.predict(X_train) #Calculating predictions\n",
    "            y_hat_test = linreg.predict(X_test) #y_pred\n",
    "            temp_train_err.append(mean_squared_error(y_train, y_hat_train)) #Calculating the MSE\n",
    "            temp_test_err .append(mean_squared_error(y_test, y_hat_test))\n",
    "        train_err.append(np.mean(temp_train_err))\n",
    "        test_err.append(np.mean(temp_test_err))\n",
    "    \n",
    "    #Outputting the average errors of 100 iterations of a random selected sample of 200 houses\n",
    "    print(\"Average Errors on 100 Models of Random 200 Sampled Houses\")\n",
    "    print(\"R^2 score:\", round(linreg.score(X, y), 2))\n",
    "    print(\"Mean absolute error (MSE):\", round(np.sum(test_err) / len(test_err), 5))\n",
    "    print(\"Root MSE:\", round(np.sqrt(np.sum(test_err) / len(test_err)), 5)) \n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"Average predicted price:\", round(y_hat_test.mean(), 4))\n",
    "    print(\"Average actual price\", round(y_test.mean(), 4))\n",
    "    \n",
    "    #Visualizing the averages of 100 iterations of a random selected sample of 200 houses\n",
    "    plt.figure(figsize = (16, 6))\n",
    "    sns.lineplot(sample, y_hat_test, label = \"Predicted prices\")\n",
    "    sns.lineplot(sample, y_test, label = \"Actual prices\")\n",
    "    plt.title(\"Comparing predicted price vs actual price\"), plt.xlabel(\"House\"), plt.ylabel(\"Prices\")\n",
    "    plt.legend(), plt.show()\n",
    "    return (linreg, y_pred, y_test)\n",
    "\n",
    "def cross_validation(X, y, cv=  15, show_scores = False):\n",
    "    score = cross_val_score(linreg, X, y, cv = cv, scoring = \"r2\")\n",
    "    print(\"Model Accuracy:\", round(sum(score) / len(score), 2) * 100, \"%\")\n",
    "    print(score) if show_scores else False\n",
    "    \n",
    "def feature_selection(X, y):\n",
    "    est = sm.OLS(y, X).fit()\n",
    "    pvalues = pd.DataFrame(est.pvalues, columns=[\"p\"])\n",
    "    features = list(pvalues[pvalues.p < 0.05].index)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape, df.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(X.info())\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(y.info())\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(df.info())\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(X_train.info())\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(X_test.info())\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(y_train.info())\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(y_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating our target and feature variables\n",
    "X = df.drop([\"Price\"] , axis = 1)\n",
    "y = pd.DataFrame(df.Price, columns=[\"Price\"]) \n",
    "\n",
    "random.seed(123)\n",
    "train_err = []\n",
    "test_err = []\n",
    "t_sizes = list(range(5, 100, 5)) #(Included start, excluded end, by size)\n",
    "linreg = LinearRegression()\n",
    "for t_size in t_sizes: #Generating 200 random samples of data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = t_size / 100)\n",
    "    linreg.fit(X_train, y_train ) #Fitting the model to the train data\n",
    "    y_hat_train = linreg.predict(X_train) #Calculating predictions\n",
    "    y_hat_test = linreg.predict(X_test)\n",
    "    train_err.append(mean_squared_error(y_train, y_hat_train)) #Calculating the MSE\n",
    "    test_err.append(mean_squared_error(y_test, y_hat_test))\n",
    "print(\"Average Test Mean Squared Error:\", np.sum(test_err)/len(test_err))\n",
    "plt.figure(figsize = (16, 6))\n",
    "plt.scatter(t_sizes, train_err, label=\"Training Error\")\n",
    "plt.scatter(t_sizes, test_err, label=\"Testing Error\")\n",
    "plt.title(\"Boston train-test-split on 1 Model\")\n",
    "plt.xlabel(\"Test Size (0 to 200)\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting function of unique values\n",
    "display(df.Sqft_Basement.value_counts(), #Outputing as a raw number\n",
    "        df.Sqft_Basement.value_counts(normalize=True)) #Outputing as a percentage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
